{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38864bit388pyenva73106303d95444eafc51aa4235c3f03",
   "display_name": "Python 3.8.8 64-bit ('3.8.8': pyenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snscrape.modules.twitter import TwitterThreadScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def clean(tweet): \n",
    "    ''' \n",
    "    Utility function to clean tweet text by removing links, special characters \n",
    "    using simple regex statements. \n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "\n",
    "def senti(tweet): \n",
    "    ''' \n",
    "    Utility function to classify sentiment of passed tweet \n",
    "    using textblob's sentiment method \n",
    "    '''\n",
    "    # create TextBlob object of passed tweet text \n",
    "    analysis = TextBlob(clean_tweet(tweet)) \n",
    "    # set sentiment \n",
    "    return analysis.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Twit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scrape = TwitterSearchScraper\n",
    "query = 'gme'\n",
    "\n",
    "gen = scrape(query + ' lang:en').get_items()\n",
    "\n",
    "tweets = [\n",
    "    next(\n",
    "        gen\n",
    "    ) for i in range(22)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = 'url date content id username outlinks outlinksss tcooutlinks tcooutlinksss'.split()\n",
    "\n",
    "[\n",
    "    dict(zip(keys, list(t)))\n",
    "    for t in tweets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['Want to buy #Bitcoin ? Join Binance the most secure US based cryptocurrency exchange! #VTHO #ALGO $XTZ #BTC #XLM $BTC $ETH #XRP #Link $Doge #ALGO #Binance $Link #Coinbase #Polkadot #DeFi #Doge #ADA #DeFi $BAT #GRT #GME #wallstreetsbets #DiamondHands',\n 'FOrgot i owned this shirt. this is definitely a sign #amc $amc #gme $GME gang GG',\n 'There id share my #gains on $gme Can’t wait to see what tomorrow will bring I like games and movies that is the hype The games will stop',\n '$PVDG Sunday afternoon is for stocks and pizza I’m sure you can relate You ever get that pizza that just hits right Better than expected? That’s gonna be this week. BIG things coming PR blitz expected any day $ILUS $AMC $GME $HCMC $SEGI $SQ',\n '$IMTL going to catch up fast 800 naked short to burn! $ltnc $hqge $tsnpd $phil $enzc $amc $nsav $cydy $nwbo $biel $hcmc $avxl $ipix $bbrw $aabb $amrn $jamn $coop $noho $xmet $vibi $fnma $sanp $innd $kblb $gme $mine $drnk #bitcoin #btc $nwgc $dbmm $wdlf $vitx $scie $pvdg $puge',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n \"When people tweet stuff out like this it just feels like they are super salty I didn't play GME or AMC but to all the people who made life changing money no amount of shit posting about how the company is failing matters.\",\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n 'My GME was down $50k but is now up$30K Thanks Melvin Gabe Vlad and Kenneth!!! #wsb #WallStreetBets',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n 'Made $25k on $GME so I’m giving away $100 to anyone who follows and retweets first 20 DM’s',\n \"It's interesting that the Dems are always against big corporations and claiming to help small businesses but the $15 MW will only benefit big companies like Walmart and will destroy mom and pop stores.\",\n 'im not simping for gme but i think this completely ignores the points bulls have Ryan Cohen is rumored to be the new cfo and has a vision to make it an online marketplace Retail stores not needed in fact its better to close them and reallocate that money on a profitable venture',\n 'The main reason I’d rather buy $UBER than $DASH is simple because while #DoorDash losses money only on driving food #uber manages at the same time to lose money on driving food AND people #Bitcoin #stonks #SundayMorning #TSLA #DOGE #GME #koss #bb #SpaceX',\n '140 short sure there was no impact there long term you right everything is normal right now with $GME inversing the entire market.',\n '$spy $spx $etsy $ndx $qqq $tsla $pltr $aapl $amzn $twtr $fb $msft $nflx $crm $penn $nvda $googl $shop $f $tdoc $pcty $gld $iyt $usd $ma $stpk $baba $spce $amc $gme #fangmant']"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "contents = [\n",
    "    clean(t.content)\n",
    "    for t in tweets\n",
    "]\n",
    "contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {\n",
    "    content: 0\n",
    "    for content in set(contents)\n",
    "}\n",
    "\n",
    "with open('labels.json', 'w') as f:\n",
    "    json.dump(labels, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        v1                                                 v2\n0      ham  Go until jurong point, crazy.. Available only ...\n1      ham                      Ok lar... Joking wif u oni...\n2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3      ham  U dun say so early hor... U c already then say...\n4      ham  Nah I don't think he goes to usf, he lives aro...\n...    ...                                                ...\n5567  spam  This is the 2nd time we have tried 2 contact u...\n5568   ham              Will Ì_ b going to esplanade fr home?\n5569   ham  Pity, * was in mood for that. So...any other s...\n5570   ham  The guy did some bitching but I acted like i'd...\n5571   ham                         Rofl. Its true to its name\n\n[5572 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>v1</th>\n      <th>v2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>ham</td>\n      <td>Will Ì_ b going to esplanade fr home?</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1587\n           1       0.93      0.92      0.92       252\n\n    accuracy                           0.98      1839\n   macro avg       0.96      0.95      0.96      1839\nweighted avg       0.98      0.98      0.98      1839\n\n"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv('spam.csv', encoding=\"latin-1\")\n",
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "df['label'] = df['class'].map({'ham': 0, 'spam': 1})\n",
    "X = df['message']\n",
    "y = df['label']\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(X) # Fit the Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#Naive Bayes Classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train,y_train)\n",
    "clf.score(X_test,y_test)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}